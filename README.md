ğŸ“ AI Lecture Summarizer

An audio-based AI application that converts lecture recordings into concise, structured summaries using speech recognition and transformer-based NLP.

This project demonstrates an end-to-end AI pipeline:
Audio â†’ Speech-to-Text â†’ NLP Summarization â†’ Readable Notes

âœ¨ Key Highlights

ğŸ§ Accepts lecture audio files (MP3 / WAV)

ğŸ—£ï¸ Converts speech to text using OpenAI Whisper

ğŸ§  Generates summaries using Transformer NLP models (BART)

ğŸ–¥ï¸ Simple and intuitive Streamlit interface

ğŸ§© Modular and clean codebase

âš™ï¸ Designed with real-world system constraints in mind

ğŸ§  System Architecture
Lecture Audio
      â†“
Speech-to-Text (Whisper)
      â†“
Text Processing
      â†“
Transformer-based Summarization (BART)
      â†“
Concise Lecture Summary


ğŸ› ï¸ Tech Stack

| Category       | Technology                       |
| -------------- | -------------------------------- |
| Language       | Python                           |
| UI             | Streamlit                        |
| Speech-to-Text | OpenAI Whisper                   |
| NLP            | Hugging Face Transformers (BART) |
| ML Framework   | PyTorch                          |


ğŸ“‚ Project Structure
ai-lecture-summarizer/
â”œâ”€â”€ app.py              # Streamlit UI
â”œâ”€â”€ transcriber.py      # Audio â†’ Text (Whisper)
â”œâ”€â”€ summarizer.py       # Text â†’ Summary (BART)
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ README.md           # Project documentation
â””â”€â”€ .gitignore

â–¶ï¸ How to Run Locally

âš ï¸ This project is intended to be run locally due to audio processing dependencies.

1ï¸âƒ£ Clone the repository
git clone https://github.com/Snehith1302/ai-lecture-summarizer.git
cd ai-lecture-summarizer

2ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the application
streamlit run app.py

ğŸ“¸ Demo (Local Execution)
<img width="1919" height="1005" alt="Screenshot 2026-01-14 232426" src="https://github.com/user-attachments/assets/25e10200-fb7d-4477-a3d7-18ab8ec2409b" />

âš ï¸ Deployment Note

This application is designed for local execution.

Speech-to-text functionality relies on Whisper, which depends on FFmpeg and system-level audio processing.
Due to limitations in managed cloud platforms, the full audio pipeline is not deployed online.

This design decision ensures:

Stability

Accurate transcription

Reproducibility of results

ğŸ¯ Use Cases

ğŸ“š Students summarizing recorded lectures

ğŸ“ Automatic note generation

ğŸ§ Audio-based content analysis

ğŸ§  Learning-focused AI applications

ğŸš€ Future Enhancements

Cloud-based speech-to-text APIs

Speaker diarization

Timestamped summaries

PDF / DOC export

Multi-language support

ğŸ‘¤ Author

Anuka Snehith Reddy
B.Tech â€“ Computer Science and Engineering
AI & ML Enthusiast

